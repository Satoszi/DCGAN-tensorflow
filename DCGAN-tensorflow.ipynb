{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550dc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7cbf566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ceb8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use specified GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as err:\n",
    "        print(err)\n",
    "\n",
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51b003dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"...\\\\celeb_dataset\"\n",
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fc68c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "975afb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45d9802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_transpose_block(inputs, num_filters, kernel_size=3, strides=2):\n",
    "    x = Conv2DTranspose(\n",
    "        filters=num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        kernel_initializer=w_init,\n",
    "        padding=\"same\",\n",
    "        strides=strides,\n",
    "        use_bias=False\n",
    "    )(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cdd9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters, kernel_size=3, padding=\"same\", strides=2, activation=True):\n",
    "    x = Conv2D(\n",
    "        filters=num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        kernel_initializer=w_init,\n",
    "        padding=padding,\n",
    "        strides=strides,\n",
    "    )(inputs)\n",
    "    \n",
    "    if activation:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = GaussianNoise(0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fc3cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    filters = [1024,512,256,128,64,32]\n",
    "\n",
    "    noise = Input(shape=(latent_dim,), name=\"latent_vector\")\n",
    "\n",
    "    x = Dense(filters[0] * 4 * 4)(noise)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Reshape((4, 4, filters[0]))(x)\n",
    "    for i in range(1, 5):\n",
    "        x = conv_transpose_block(x,num_filters=filters[i])\n",
    "        \n",
    "    x = conv_block(x,\n",
    "        num_filters=3,\n",
    "        strides=1,\n",
    "        activation=False\n",
    "    )\n",
    "    fake_output = Activation(\"tanh\")(x)\n",
    "    return Model(noise, fake_output, name=\"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71db0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_generator(latent_dim).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f826b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    filters = [128, 256, 512,1024]\n",
    "    \n",
    "    image_input = Input(shape=(IMG_H, IMG_W, 3))\n",
    "    x = image_input\n",
    "\n",
    "    for i in range(0, 4):\n",
    "        x = conv_block(x, num_filters=filters[i])\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    return Model(image_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "141cb0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b897892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_function):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_function = loss_function\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        \n",
    "        for _ in range(2):\n",
    "            \n",
    "            ## Discriminator step - fake images\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim)) \n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            generated_labels = tf.zeros((batch_size, 1))\n",
    "            with tf.GradientTape() as ftape:\n",
    "                predictions = self.discriminator(generated_images)\n",
    "                df_loss = self.loss_function(generated_labels, predictions)\n",
    "            grads = ftape.gradient(df_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "            ## Generator step\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            misleading_labels = tf.ones((batch_size, 1))\n",
    "            with tf.GradientTape() as gtape:\n",
    "                predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "                g_loss = self.loss_function(misleading_labels, predictions)\n",
    "            grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n",
    "            self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "            \n",
    "            ## Discriminator step - real images\n",
    "            labels = tf.ones((batch_size, 1))\n",
    "            with tf.GradientTape() as rtape:\n",
    "                predictions = self.discriminator(real_images)\n",
    "                dr_loss = self.loss_function(labels, predictions)\n",
    "            grads = rtape.gradient(dr_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "            \n",
    "            ## Generator step\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            misleading_labels = tf.ones((batch_size, 1))\n",
    "            with tf.GradientTape() as gtape:\n",
    "                predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "                g_loss = self.loss_function(misleading_labels, predictions)\n",
    "            grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n",
    "            self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "            \n",
    "            return {\"df_loss\": df_loss, \"dr_loss\": dr_loss, \"g_loss\": g_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9be7f2",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db716f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create a data loader to not overwhelm the ram\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  shuffle = True,\n",
    "  image_size=(IMG_W, IMG_H),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5620d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset normalization\n",
    "\n",
    "def preprocessing_image(img):\n",
    "    img = (img - 127.5) / 127.5\n",
    "    return img\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: preprocessing_image(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47a66094",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 16\n",
    "noise = np.random.normal(size=(n_samples, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d703a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(examples, index, n):\n",
    "    examples = (examples + 1) / 2.0 # normalize from (-1, 1) range to (0, 1) range\n",
    "    fig = pyplot.figure(figsize=(32, 32))\n",
    "    #n = 4\n",
    "    for i in range(n * n):\n",
    "        fig.add_subplot(n, n, i+1)\n",
    "        pyplot.axis(\"off\")\n",
    "        image = examples[i]\n",
    "        pyplot.imshow(image)\n",
    "    filename = f\"samples/generated_plot_index-{index}.png\"\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b220dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = []\n",
    "global index\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c159d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_callback(keras.callbacks.Callback):\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        global index\n",
    "        training_history.append(logs)\n",
    "        \n",
    "        if (batch % 500 == 499):\n",
    "            index += 1\n",
    "            examples = g_model.predict(noise)\n",
    "            save_plot(examples, index, int(np.sqrt(n_samples)))\n",
    "            g_model.save(f\"checkpoints/g_model_{str(index)}.h5\")\n",
    "            d_model.save(f\"checkpoints/d_model_{str(index)}.h5\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc330d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66016eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = build_discriminator()\n",
    "g_model = build_generator(latent_dim)\n",
    "#d_model = tf.keras.models.load_model('checkpoints/d_model_0.h5')\n",
    "#g_model = tf.keras.models.load_model('checkpoints/g_model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23506840",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(d_model, g_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cbc42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n",
    "d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "dcgan.compile(d_optimizer, g_optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ce6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan.fit(normalized_ds, epochs=10, shuffle=True,\n",
    "        callbacks=[custom_callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e906fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = [i['df_loss'] for i in training_history]\n",
    "dr_loss = [i['dr_loss'] for i in training_history]\n",
    "g_loss = [i['g_loss'] for i in training_history]\n",
    "\n",
    "df_loss_ma = np.convolve(df_loss, np.ones(1000)/1000, 'valid')\n",
    "dr_loss_ma = np.convolve(dr_loss, np.ones(1000)/1000, 'valid')\n",
    "g_loss_ma = np.convolve(g_loss, np.ones(1000)/1000, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97081be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(1, figsize = (30,20)) \n",
    "    \n",
    "pyplot.subplot(221)  \n",
    "pyplot.plot(df_loss_ma)  \n",
    "pyplot.plot(dr_loss_ma)  \n",
    "pyplot.plot(g_loss_ma)  \n",
    "pyplot.title('DCGAN losses')  \n",
    "pyplot.ylabel('Binary crossentropy loss')  \n",
    "pyplot.xlabel('batch number')  \n",
    "pyplot.legend(['discriminator fake loss', 'discriminator real loss', \"generator loss\"]) \n",
    "\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
